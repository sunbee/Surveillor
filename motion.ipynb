{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect motion with PIL based on the recipe for OpenCV in the reference. This is because installing OpenCV on Raspberry Pi is a bear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from picamera import PiCamera, array\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageFilter, ImageMorph, ImageEnhance\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect motion by imaging in two takes, one after the other, and comparing pixels. Let's write a function to take a snap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_motion_snap(width, height):\n",
    "    with PiCamera() as Eye:\n",
    "        time.sleep(1)\n",
    "        Eye.resolution = (width, height)\n",
    "        Eye.rotation = 180\n",
    "        with array.PiRGBArray(camera=Eye) as Stream:\n",
    "            Eye.exposure_mode = 'auto'\n",
    "            Eye.awb_mode = 'auto'\n",
    "            Eye.capture(Stream, format='rgb')\n",
    "            return Stream.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an image with width, height as 300, 300.\n"
     ]
    }
   ],
   "source": [
    "test = take_motion_snap(300, 300)\n",
    "print(\"Got an image with width, height as {}, {}.\".format(test.shape[0], test.shape[1]))\n",
    "snap = Image.fromarray(test)\n",
    "snap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an RGB image of the specified height and width as a 3-dimensional numpy array. We want to take the difference between two snaps. Write a wrapper function to use ```take_motion_snap(w, h)```, take two snaps and return the computed difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_two_motion(intervalsec):\n",
    "    im_one = take_motion_snap(300, 300)\n",
    "    tic = time.time()\n",
    "    toc = tic\n",
    "    while (toc - tic) < intervalsec:\n",
    "        toc = time.time()\n",
    "    im_two = take_motion_snap(300, 300)\n",
    "    im_diff = np.subtract(im_two, im_one)\n",
    "    return im_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a difference of width, height as 300, 300.\n",
      "The median, mean diff are 3.00, 105.64.\n"
     ]
    }
   ],
   "source": [
    "test_diff = take_two_motion(6)\n",
    "print(\"Got a difference of width, height as {}, {}.\".format(test_diff.shape[0], test_diff.shape[1]))\n",
    "print(\"The median, mean diff are {:.2f}, {:.2f}.\".format(np.median(test_diff), np.mean(test_diff)))\n",
    "snap = Image.fromarray(test_diff)\n",
    "snap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply thresholding to remove noise from motion and nuisance effects such as lighting change. In thresholding, we will set the value of a pixel in each of the RGB channels to 0 (min) or 255 (max) accordng to a binary threshold value. In OpenCV, this operation would be ```cv2.threshold(frame_delta, 50, 255, cv2.THRESH_BINARY)```. Use numpy operations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_difference(imdiff, threshold=50):\n",
    "    return np.uint8(np.where(imdiff > threshold, 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a thresholded image of width, height as 300, 300.\n"
     ]
    }
   ],
   "source": [
    "diff_clean = threshold_difference(test_diff, np.mean(test_diff))\n",
    "print(\"Got a thresholded image of width, height as {}, {}.\".format(diff_clean.shape[0], diff_clean.shape[1]))\n",
    "diff_clean.dtype\n",
    "snap = Image.fromarray(diff_clean)\n",
    "snap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform erosion and dilation operations to improve signal-to-noise. Apply the PIL methods ```minFilter()``` and ```MaxFilter()```for erosion and dilation respectively. Then, convert the image to black-and-white using the ```convert()``` method. All these methods are of the nature of image filters and operate on image as opposed to numpy array. Mutate accordingly. Get the result as a 2D numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_dilate(snap, showme=False):\n",
    "    snap_eroded = snap.filter(ImageFilter.MinFilter(7))\n",
    "    if showme:\n",
    "        snap_eroded.show()\n",
    "        print(\"After erosion, got median, mean as {:.2f}, {:.2f}.\".format(np.median(snap_eroded), np.mean(snap_eroded)))\n",
    "    snap_dilated = snap_eroded.filter(ImageFilter.MaxFilter(3))\n",
    "    if showme:\n",
    "        snap_dilated.show()\n",
    "        print(\"After dilation, got median, mean as {:.2f}, {:.2f}.\".format(np.median(snap_dilated), np.mean(snap_dilated)))\n",
    "    snap_bnw = snap_dilated.convert('1')\n",
    "    if showme:\n",
    "        snap_bnw.show()\n",
    "        print(\"B&W image for motion detection has dimensions {}\".format(bnw_array.shape))\n",
    "    bnw_array = np.array(snap_bnw)\n",
    "    return bnw_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       [False, False, False, ..., False,  True,  True]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bnw = erode_dilate(snap)\n",
    "test_bnw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we havd 2D mask with connected regions, let us find the connected components, count them, then rank and sort them. This will give us an idea of whether there is motion in the image. We will use the algorithm in Aaron Becker's [instructional video](https://youtu.be/ticZclUYy88). \n",
    "\n",
    "This approach consists of two raster scans of the image. In the first scan, a foreground pixel is assigned a proposed membership label. As some of these labels may refer to the same connected component due to the nature of rastering, synonyms are noted and a second pass is made to update and finalze labels. Further details are explained in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreground has 559 pixels and procesed 559 in 1st pass.\n",
      "First pass found 132 candidates in first pass.\n",
      "Detected 9 connected components.\n"
     ]
    }
   ],
   "source": [
    "test_pass = np.zeros(test_bnw.shape, dtype = np.int32)  # Mask \n",
    "count_foreground = 0\n",
    "first_pass_counter = 0\n",
    "synonyms = {}\n",
    "\n",
    "for idx,x in np.ndenumerate(test_bnw):\n",
    "    aboveme = False     # B&W background\n",
    "    leftofme = False    # B&W background\n",
    "    A = 0           # Label none\n",
    "    B = 0           # Label none\n",
    "    if x: # Not background\n",
    "        \"\"\"\n",
    "        Is there a pixel above or to the left that is not background?\n",
    "        Check and if found, obtain the numeric labels \n",
    "        marking connected components in 1st pass.\n",
    "        \"\"\"\n",
    "        count_foreground += 1\n",
    "        if (idx[0] > 0): # Yes, above\n",
    "            aboveme = test_bnw[idx[0]-1, idx[1]]\n",
    "            A = test_pass[idx[0]-1, idx[1]] # Get label\n",
    "        if (idx[1] > 0): # Yes, on left\n",
    "            leftofme = test_bnw[idx[0], idx[1]-1]\n",
    "            B = test_pass[idx[0], idx[1]-1] # Get label\n",
    "        \"\"\"\n",
    "        If both left and above have foreground,\n",
    "        stick the lesser number as the label on our pixel.\n",
    "        Note the conflict for 2nd pass correction.\n",
    "        Note that if the lower value has already been marked\n",
    "        for correction, follow the chain to the lowest value\n",
    "        in the dictionary of synonymous labels.\n",
    "        If only one of left or above have foreground,\n",
    "        stick that label on our pixel.\n",
    "        Otherwise, mint a new label and stick it on.\n",
    "        \"\"\"\n",
    "        if (aboveme and leftofme): # Contest if not A = B          \n",
    "            test_pass[idx] = min(A, B) # Resolve\n",
    "            if (A != B): # Note for update in second pass\n",
    "                if synonyms.get(min(A, B)):\n",
    "                    synonyms[max(A, B)] = synonyms.get(min(A, B))\n",
    "                else:\n",
    "                    synonyms[max(A, B)] = min(A, B)\n",
    "        elif aboveme:\n",
    "            test_pass[idx] = A\n",
    "        elif leftofme:\n",
    "            test_pass[idx] = B        \n",
    "        else:\n",
    "            first_pass_counter += 1 # New label\n",
    "            test_pass[idx] = first_pass_counter\n",
    "            \n",
    "print(\"Foreground has {} pixels and procesed {} in 1st pass.\".format(sum(sum(test_bnw)), count_foreground))\n",
    "print(\"First pass found {} candidates in first pass.\".format(first_pass_counter))\n",
    "Image.fromarray(test_pass).show()\n",
    "print(\"Detected {} connected components.\".format(len(set(synonyms.values()) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components = {}\n",
    "for idx,x in np.ndenumerate(test_pass):\n",
    "    \"\"\"\n",
    "    Execute 2nd raster scan and update labels\n",
    "    using the synonyms dictionary. \n",
    "    \"\"\"\n",
    "    if x > 0: # Labeled\n",
    "        label = synonyms.get(x, 0) \n",
    "        if label > 0: # Synonym found for label\n",
    "            test_pass[idx] = label \n",
    "            connected_components[label] = connected_components.get(label, 0) + 1\n",
    "        else:\n",
    "            connected_components[x] = connected_components.get(x, 0) + 1\n",
    "Image.fromarray(test_pass).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found {86: 237, 1: 129} connected components above size-threshold of 90.\n",
      "Completed 2nd pass and ccounted for 559 pixels.\n"
     ]
    }
   ],
   "source": [
    "size_threshold = 90\n",
    "result = {label: connected_components[label] \\\n",
    "        for label in sorted(connected_components, key=connected_components.get, reverse=True) \\\n",
    "        if connected_components[label] > size_threshold}\n",
    "print(\"Found {} connected components above size-threshold of {}.\".format(result, size))\n",
    "print(\"Completed 2nd pass and ccounted for {} pixels.\".format(sum(connected_components.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we can call motion detected when the sum of sizes of connected components above a size threshold (say, 90px or 0.1% of image size) is greater than a threshold (say, 4500 or 5% of image size). Let's proceed to write a function to perform the 2-pass detection of connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connected_components(imbnw, showme=False):\n",
    "    mask = np.zeros(imbnw.shape, dtype = np.int32)  # Mask \n",
    "    count_foreground = 0\n",
    "    first_pass_counter = 0\n",
    "    synonyms = {}\n",
    "\n",
    "    for idx, x in np.ndenumerate(imbnw):\n",
    "        aboveme = False     # B&W background\n",
    "        leftofme = False    # B&W background\n",
    "        A = 0           # Label none\n",
    "        B = 0           # Label none\n",
    "        if x: # Not background\n",
    "            \"\"\"\n",
    "            Is there a pixel above or to the left that is not background?\n",
    "            Check and if found, obtain the numeric labels \n",
    "            marking connected components in 1st pass.\n",
    "            \"\"\"\n",
    "            count_foreground += 1\n",
    "            if (idx[0] > 0): # Yes, above\n",
    "                aboveme = imbnw[idx[0]-1, idx[1]]\n",
    "                A = mask[idx[0]-1, idx[1]] # Get label\n",
    "            if (idx[1] > 0): # Yes, on left\n",
    "                leftofme = imbnw[idx[0], idx[1]-1]\n",
    "                B = mask[idx[0], idx[1]-1] # Get label\n",
    "            \"\"\"\n",
    "            If both left and above have foreground,\n",
    "            stick the lesser number as the label on our pixel.\n",
    "            Note the conflict for 2nd pass correction.\n",
    "            Note that if the lower value has already been marked\n",
    "            for correction, follow the chain to the lowest value\n",
    "            in the dictionary of synonymous labels.\n",
    "            If only one of left or above have foreground,\n",
    "            stick that label on our pixel.\n",
    "            Otherwise, mint a new label and stick it on.\n",
    "            \"\"\"\n",
    "            if (aboveme and leftofme): # Contest if not A = B          \n",
    "                mask[idx] = min(A, B) # Resolve\n",
    "                if (A != B): # Note for update in second pass\n",
    "                    if synonyms.get(min(A, B)):\n",
    "                        synonyms[max(A, B)] = synonyms.get(min(A, B))\n",
    "                    else:\n",
    "                        synonyms[max(A, B)] = min(A, B)\n",
    "            elif aboveme:\n",
    "                mask[idx] = A\n",
    "            elif leftofme:\n",
    "                mask[idx] = B        \n",
    "            else:\n",
    "                first_pass_counter += 1 # New label\n",
    "                mask[idx] = first_pass_counter\n",
    "\n",
    "    if showme:\n",
    "        Image.fromarray(mask).show()\n",
    "\n",
    "    connected_components = {}\n",
    "    \n",
    "    for idx,x in np.ndenumerate(mask):\n",
    "        \"\"\"\n",
    "        Execute 2nd raster scan and update labels\n",
    "        using the synonyms dictionary. \n",
    "        \"\"\"\n",
    "        if x > 0: # Labeled\n",
    "            label = synonyms.get(x, 0) \n",
    "            if label > 0: # Synonym found for label\n",
    "                mask[idx] = label \n",
    "                connected_components[label] = connected_components.get(label, 0) + 1\n",
    "            else:\n",
    "                connected_components[x] = connected_components.get(x, 0) + 1\n",
    "    \n",
    "    if showme:\n",
    "        Image.fromarray(test_pass).show()\n",
    "    \n",
    "    return connected_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_connect_components(regions, size_threshold):\n",
    "    size = 90\n",
    "    result = {label: regions[label] \\\n",
    "        for label in sorted(regions, key=regions.get, reverse=True) \\\n",
    "        if regions[label] > size_threshold}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find the connected regions and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found {86: 237, 1: 129} connected components above size-threshold of 90.\n",
      "Completed 2nd pass and accounted for 559 pixels.\n"
     ]
    }
   ],
   "source": [
    "cc = find_connected_components(test_bnw, showme=True)\n",
    "res = analyze_connect_components(cc, 90)\n",
    "print(\"Found {} connected components above size-threshold of 90.\".format(result))\n",
    "print(\"Completed 2nd pass and accounted for {} pixels.\".format(sum(cc.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can detect motion easily and reliably by this approac with the following steps:\n",
    "1. Grab two snapshots in rgb in quick succession, size 300 x 300 pixels.\n",
    "2. Calculate the difference.\n",
    "3. Apply thresholding in all color channels.\n",
    "4. Perform erosion followed by dilation on rgb image to improve signal-noise and convert to B&W.\n",
    "5. Identify connected regions using 2-pass approach, count and order by size.\n",
    "Applying a logical rule to the result, such as summing the sizes of top 5 regions and comparing with a threshold (say, 5 percent of image size or 4500 pixels), after filtering to remove all regions less that a size threshold (say, 0.1% of image size or 90 pixels), detects motion.\n",
    "\n",
    "We have a function for each step that serves as the model for methods of a motion detection class. In the next step, implement the module based on the development in this notebook. Then, we will create another Jupyter notebook to use the module and show results of different test scenarios, i.e. cases and controls, with images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. A comprehensive DIY [guide](http://drsol.com/~deid/pi/camera/index.html) to Pi camera including many lesser-known techniques for image and video recording, processing and sharing.\n",
    "2. A github [repo](https://gist.github.com/FutureSharks/ab4c22b719cdd894e3b7ffe1f5b8fd91) for pro motion detection with OpenCV.\n",
    "3. A stackoverflow.com [post](https://stackoverflow.com/questions/31064974/whats-the-fastest-way-to-threshold-a-numpy-array) upon thresholding with operations upon numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 32-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
